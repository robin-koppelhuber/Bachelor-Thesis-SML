# @package _global_
model:
  name: roberta_base
  architecture: roberta
  hf_model_id: FacebookAI/roberta-base

  # Model loading
  loading:
    cache_dir: ${paths.hf_models_cache_base}
    torch_dtype: auto # auto, float32, float16, bfloat16
    device_map: null # null, auto, or custom device mapping
    trust_remote_code: false

  # Performance optimization
  optimization:
    use_torch_compile: false # Enable torch.compile() for performance (PyTorch 2.0+, not supported on Windows)
    torch_compile_mode: default # default, reduce-overhead, max-autotune (for training)
    torch_compile_mode_eval: default # Compile mode for evaluation/inference

  # Task vector computation
  task_vectors:
    computation_method: subtract # subtract = fine_tuned - base
    normalize: false
    save_dtype: float32
